---
title: Value-Based Deep RL Scales Predictably
link: https://arxiv.org/abs/2502.04327
date: 2025-05-03
highlight: true
image_before: qscaled_before.png
image_after: qscaled_after.gif
---

[Oleh Rybkin](https://people.eecs.berkeley.edu/~oleh/), 
[Michal Nauman](https://scholar.google.com/citations?user=GnEVRtQAAAAJ&hl=en), 
**Preston Fu**, 
[Charlie Snell](https://sea-snell.github.io/), 
[Pieter Abbeel](https://people.eecs.berkeley.edu/~pabbeel/), 
[Sergey Levine](https://people.eecs.berkeley.edu/~svlevine/), 
[Aviral Kumar](https://aviralkumar2907.github.io/)

*International Conference on Machine Learning (ICML)*, 2025 \
*ICLR Robot Learning Workshop*, 2025 (**oral presentation**)

[arXiv](https://arxiv.org/abs/2502.04327) / [Poster](https://people.eecs.berkeley.edu/~oleh/images/qscaled_poster.pdf) / [Thread](https://x.com/_oleh/status/1889016893140516880)

We build empirical models of the data-compute Pareto frontier, optimal resource
allocation across data and compute, and hyperparameter dependencies for value-based
RL. From small-scale runs, we can extrapolate towards higher data, compute, and
performance.